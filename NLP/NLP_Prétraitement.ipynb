{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4gQp1IfOh+RxwzaRiBGmg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjOx4IjlBTzQ","executionInfo":{"status":"ok","timestamp":1701177193423,"user_tz":-60,"elapsed":272,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"90f2272d-c519-4d95-f400-87fe5e460778"},"outputs":[{"output_type":"stream","name":"stdout","text":["Bonjour, tout le Monde ... ! @Python #NLP\n","Bonjour tout le Monde   Python NLP\n"]}],"source":["## Python regex : re\n","# https://www.pythontutorial.net/python-regex/python-regex-sub/\n","import re\n","texte = \"Bonjour, tout le Monde ... ! @Python #NLP\"\n","texte_propre = re.sub(r'[^\\w\\s]', '', texte)\n","texte_propre1 = re.sub(r'\\d', '', texte)\n","print(texte_propre1)\n","print(texte_propre)\n"]},{"cell_type":"markdown","source":["#Conversion du texte en minuscules (Standardisation)\n","La conversion de tout le texte en minuscules garantit que votre modèle traite les mots comme \"Python\", \"python\", etc.\n"],"metadata":{"id":"KIhF_tJUFDx_"}},{"cell_type":"code","source":["\n","## https://www.pythontutorial.net/python-string-methods/python-string-lower/\n","## Voici comment vous pouvez conertir du texte en minuscules en Python :\n","texte = \"Bonjour, Monde ! @Python #NLP\"\n","texte_minuscule = texte.lower()\n","print(texte_minuscule) ## Sortie : \"bonjour, monde ! @python #nlp\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wikHRbtD1P3","executionInfo":{"status":"ok","timestamp":1701177499880,"user_tz":-60,"elapsed":357,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"e59c0b4d-db69-4e93-df3f-1cd84a64e133"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["bonjour, monde ! @python #nlp\n"]}]},{"cell_type":"markdown","source":["#Conversion du texte en majiscules  (Standardisation)\n","La conversion de tout le texte en minuscules garantit que votre modèle traite les mots comme \"Python\", \"python\", etc.\n"],"metadata":{"id":"zAmWR7sKFbwB"}},{"cell_type":"code","source":["\n","## https://www.pythontutorial.net/python-string-methods/python-string-lower/\n","## Voici comment vous pouvez conertir du texte en minuscules en Python :\n","texte = \"Bonjour, Monde ! @Python #NLP\"\n","texte_maji = texte.upper()\n","print(texte_maji) ## Sortie : \"bonjour, monde ! @python #nlp\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-6AziOKFkUA","executionInfo":{"status":"ok","timestamp":1701177685679,"user_tz":-60,"elapsed":288,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"9da5b791-1578-4d97-d87e-8dae64e672b1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["BONJOUR, MONDE ! @PYTHON #NLP\n"]}]},{"cell_type":"markdown","source":["#Tokenisation (Rappel)\n","La tokenisation est le processus de découpage du texte en mots ou en jetons individuels. Il s'agit souvent l'une des premières étapes du\n","nettoyage de texte et du NLP. La bibliothèque NLTK de Python offre un moyen simple de tokeniser le texte :"],"metadata":{"id":"PF-PAO02Gfat"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cBWYGzFGuB6","executionInfo":{"status":"ok","timestamp":1701177915263,"user_tz":-60,"elapsed":2693,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"d076b640-ea1b-4090-8d4d-72269b2225ff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":[],"metadata":{"id":"J50utn8jF96z"}},{"cell_type":"code","source":["#Tokenisation avec word_tokenize\n","from nltk.tokenize import word_tokenize\n","texte = \"Bonjour, Monde ! @Python #NL,P i'm\"\n","jetons = word_tokenize(texte)\n","print(jetons)\n","## Sortie : ['Bonjour', ',', 'Monde', '!', '@Python', '#NLP']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qcHHHCkGYGT","executionInfo":{"status":"ok","timestamp":1701179130302,"user_tz":-60,"elapsed":372,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"57d0fd49-8b97-4677-e972-d261b8cf3691"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["['Bonjour', ',', 'Monde', '!', '@', 'Python', '#', 'NL', ',', 'P', 'i', \"'m\"]\n"]}]},{"cell_type":"code","source":["#Tokenisation avec wordpunct_tokenize\n","#faite refernce aussi pour caractere speciel like '\n","from nltk.tokenize import wordpunct_tokenize\n","S = \"Bonjour, Monde ! @Python #NLP , i'm\"\n","wordpunct_tokenize(S)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sswH0vQFIfrs","executionInfo":{"status":"ok","timestamp":1701179389248,"user_tz":-60,"elapsed":319,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"4de30963-6526-4ed7-d175-cd4b4a58d391"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Bonjour', ',', 'Monde', '!', '@', 'Python', '#', 'NLP', ',', 'i', \"'\", 'm']"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["#Suppression des mots vides\n","Les mots vides sont des mots courants comme \"est\", \"le\" et \"et\" qui n'ont souvent pas beaucoup de signification sémantique. Les supprimer\n","peut aider à réduire la dimensionnalité de vos données. NLTK fournit une liste de mots vides courants en anglais que vous pouvez utiliser :\n"],"metadata":{"id":"BNl63EpPMtaj"}},{"cell_type":"code","source":[" nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evFWx12ANt8f","executionInfo":{"status":"ok","timestamp":1701181136142,"user_tz":-60,"elapsed":299,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"031fa09b-a29f-4e52-a44b-077edd111537"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":[],"metadata":{"id":"uyxAO_PjGqJF"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","mots_vides = set(stopwords.words('english') )\n","texte = \"that  is NLP course and so  .\"\n","jetons = word_tokenize(texte)\n","jetons_filtres = [jeton for jeton in jetons if jeton not in mots_vides]\n","print(jetons_filtres) ## Sortie : ['Ceci', 'phrase', 'exemple', '.']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Us9QQeHoM60y","executionInfo":{"status":"ok","timestamp":1701181136819,"user_tz":-60,"elapsed":2,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"91118cb9-2dc5-4e70-ee6b-bae8b09e54ae"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["['NLP', 'course', '.']\n"]}]},{"cell_type":"markdown","source":["#Racinisation et lemmatisation - Normalisation : (Stemming & Lemmatisation)\n","La racinisation et la lemmatisation sont des techniques permettant de réduire les mots à leur forme racine. Cela peut aider à réduire la\n","dimensionnalité de vos données et à regrouper différentes formes du même mot.\n","La normalisation est le processus par lequel les jetons sont convertis dans leur forme de base. Lors de la normalisation, la flexion est\n","supprimée du mot pour obtenir sa forme de base.\n","L'objectif de la normalisation est de réduire les variations du texte qui n'ont pas de signification significative mais qui peuvent affecter la\n","précision des tâches de PNL. Différentes formes de normalisation sdat utilisées pour relever des défis spécifiques dans le traitement de texte.\n","Pour des exemples,\n","suis, suis, est => être\n","chat, chats, chat, chat => chat\n","Voici comment vous pouvez effectuer une racinisation et une lemmatisation à l'aide de NLTK :\n"],"metadata":{"id":"_4mVVHnvQJjR"}},{"cell_type":"markdown","source":["#Racines"],"metadata":{"id":"cxdFV0VvRE5r"}},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt')\n","\n","# Sample sentence\n","sentence = \"frogs are dancing and dogs are singing.\"\n","tokens = word_tokenize(sentence)\n","\n","# Stemmers\n","print(\"witch french\")\n","stemmers = [PorterStemmer(), LancasterStemmer(), SnowballStemmer(\"french\")]\n","\n","for stemmer in stemmers:\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","    print(f\"{stemmer.__class__.__name__} Stemmed Tokens:\", stemmed_tokens)\n","\n","print(\"witch english\")\n","\n","stemmers = [PorterStemmer(), LancasterStemmer(), SnowballStemmer(\"english\")]\n","\n","for stemmer in stemmers:\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","    print(f\"{stemmer.__class__.__name__} Stemmed Tokens:\", stemmed_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCEq_W9-QKwQ","executionInfo":{"status":"ok","timestamp":1701181176441,"user_tz":-60,"elapsed":546,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"6f5ffd1e-76f5-4bd9-c6dc-be6d1e5729e2"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["witch french\n","PorterStemmer Stemmed Tokens: ['frog', 'are', 'danc', 'and', 'dog', 'are', 'sing', '.']\n","LancasterStemmer Stemmed Tokens: ['frog', 'ar', 'dant', 'and', 'dog', 'ar', 'sing', '.']\n","SnowballStemmer Stemmed Tokens: ['frog', 'are', 'dancing', 'and', 'dog', 'are', 'singing', '.']\n","witch english\n","PorterStemmer Stemmed Tokens: ['frog', 'are', 'danc', 'and', 'dog', 'are', 'sing', '.']\n","LancasterStemmer Stemmed Tokens: ['frog', 'ar', 'dant', 'and', 'dog', 'ar', 'sing', '.']\n","SnowballStemmer Stemmed Tokens: ['frog', 'are', 'danc', 'and', 'dog', 'are', 'sing', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["#Lemmes\n","Vous pouvez choisir l'un des lemmatisants ci-dessous selon vos besoins :\n","Lemmatiseur Wordnet Lemmatiseur spatial TextBlob Modèle CLIPS Stanford CorePNL Gensim Lemmatiseur ArbreTagger Nous allons utiliser la\n","bibliothèque NLTK pour effectuer une lemmatisation à l'aide de WordnetLemmatizer. Il symbolise d'abord la phrase, puis la lemmatise pour\n","trouver des mots de base significatifs dans le vocabulaire, puis les remet pour imprimer la phrasellemmatisee.\n"],"metadata":{"id":"R8zg0M3BTfRz"}},{"cell_type":"code","source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"metadata":{"id":"tlJ1glJ9UMWR","executionInfo":{"status":"ok","timestamp":1701181444177,"user_tz":-60,"elapsed":345,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"0f2181a5-4181-4c0d-f844-5cf92af3f197","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["\n","\n","# Create a lemmatizer object\n","lemmatizer = WordNetLemmatizer()\n","# Sample sentence\n","sentence = \"boys are running and mosquitos are flying.\"\n","# Tokenize the sentence\n","tokens = word_tokenize(sentence)\n","# Lemmatize the tokens\n","lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","# Join the lemmatized tokens to form a sentence\n","lemmatized_sentence = \" \".join(lemmatized_tokens)\n","print(\"Original Sentence:\", sentence)\n","print(\"Lemmatized Sentence:\", lemmatized_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7V25qqPPTgi8","executionInfo":{"status":"ok","timestamp":1701181447098,"user_tz":-60,"elapsed":263,"user":{"displayName":"Abdelaziz Rachidi","userId":"05306956979074411334"}},"outputId":"1297dcf5-d3d5-4429-ae38-a27018b41c5d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence: boys are running and mosquitos are flying.\n","Lemmatized Sentence: boy are running and mosquito are flying .\n"]}]}]}